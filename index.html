<!DOCTYPE HTML>
<html lang="en">
<head>
    <meta charset="UTF-8"/>
    <title>Shuyao Shang</title>
    <meta name="author" content="Shuyao Shang"/>
    <meta name="viewport" content="width=device-width, initial-scale=1"/>
    <link rel="shortcut icon" href="images/favicon/arrow.ico" type="image/x-icon"/>
    <link rel="stylesheet" type="text/css" href="stylesheet.css"/>
</head>

<body>
<!-- 页面最大宽度容器 -->
<table style="width:100%;max-width:800px;border:0;border-spacing:0;border-collapse:separate;margin:0 auto;">
    <tbody>
    <tr>
        <td style="padding:0">

            <!-- 头部：姓名 + 简介 + 联系方式 / 头像 -->
            <table style="width:100%;border:0;border-spacing:0;border-collapse:separate;margin:0 auto;">
                <tbody>
                <tr>
                    <!-- 左：文字 -->
                    <td style="padding:2.5%;width:63%;vertical-align:middle">
                        <p class="name" style="text-align:center;">Shuyao Shang</p>
                        <p>
                            I'm a second-year Ph.D. student at the
                            <a href="https://nlpr.ia.ac.cn/cn/" target="_blank" rel="noopener"> NLPR, Institute of
                                Automation, Chinese Academy of Sciences (CASIA)</a>
                            in Beijing, supervised by Prof. <a href="https://people.ucas.ac.cn/~tantieniu"
                                                               target="_blank">Tieniu Tan</a> and Prof. <a
                                href="https://zhaoxiangzhang.net" target="_blank">Zhaoxiang Zhang</a>.
                        </p>
                        <p>
                            My research interests span
                            <strong>End-to-end autonomous driving</strong>,
                            <strong>Reinforcement learning</strong>, and
                            <strong>World models</strong>.
                            I am committed to developing intelligent agents that can autonomously evolve intelligence in
                            open-world exploration, and <a href="https://www.bilibili.com/video/BV1yMkEYBEPD"><em>"Pursuing the Nature of Intelligence"</em> </a>.

                        </p>

                        <div style="text-align:center; font-size:0.9em; line-height:1.35; margin:0.5rem 0 1rem;">
                          $$\text{Knowledge}=\int_{0}^{t}\text{Intelligence}\,\mathrm{d}t$$
                          $$\text{Intelligence}=\frac{\mathrm{d}}{\mathrm{d}t}\text{Knowledge}.$$
                        </div>



                        <!-- 引入 MathJax 渲染公式 -->
                        <script>
                            window.MathJax = {
                                tex: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
                            };
                        </script>
                        <script id="MathJax-script" async
                                src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
                        </script>


                        <p style="text-align:center">
                            <a href="mailto:shangshuyao2024@ia.ac.cn">Email</a> &nbsp;/&nbsp;
                            <!--                    <a href="data/ShuyaoShang-CV.pdf">CV</a> &nbsp;/&nbsp;-->
                            <a href="https://scholar.google.com/citations?hl=en&user=qrfnCawAAAAJ">Scholar</a> &nbsp;/&nbsp;
                            <a href="https://github.com/yaoyao-jpg/">Github</a> &nbsp;/&nbsp;
                            <a href="https://www.zhihu.com/people/shang-shu-yao-81">Zhihu</a>
                        </p>
                    </td>

                    <td style="padding:2.5%;width:37%;max-width:37%">
                        <a href="images/ShuyaoShang.jpg">
                            <img
                                    src="images/ShuyaoShang.jpg"
                                    alt="profile photo"
                                    style="width:100%;max-width:100%;object-fit:cover;border-radius:50%;"
                                    class="hoverZoomLink"
                            />
                        </a>
                    </td>
                </tr>
                </tbody>
            </table>

            <!-- Research 简介 -->
            <table style="width:100%;border:0;border-spacing:0;border-collapse:separate;margin:0 auto;">
                <tbody>
                <tr>
                    <td style="padding:16px;width:100%;vertical-align:middle">
                        <h2>Publications</h2>
                        <!--                        <p>* indicates equal contribution</p>-->
                    </td>
                </tr>
                </tbody>
            </table>

            <!-- Publications -->
            <table style="width:100%;border:0;border-spacing:0 10px;border-collapse:separate;margin:0 auto;">
                <tbody>

                <tr>
                    <td style="padding:20px;width:30%;max-width:30%" align="center">
                        <img style="width:100%;max-width:100%" src="images/DynVLA.png" alt="DynVLA">
                    </td>
                    <td style="padding:16px;width:100%;vertical-align:middle">
                        <a href="" target="_blank" rel="noopener">
                            <span class="papertitle">DynVLA: Learning World Dynamics for Action Reasoning in Autonomous Driving</span>
                        </a>
                        <br/>
                        <span><strong>Shuyao Shang</strong><sup>*</sup>, Bing Zhan<sup>*</sup>, Yunfei Yan, Yuqi Wang, Yingyan Li, Yasong An, Xiaoman Wang, Jierui Liu, Lu Hou, Lue Fan<sup>†</sup>, Zhaoxiang Zhang<sup>†</sup>, Tieniu Tan</span>
                        <br/>
                        <strong><em>Under Review</em>, 2026</strong>
                        <br>
                        <p>
                            <em>
                               A Dynamics CoT-based VLA model that reasons over compact future dynamics for autonomous driving.
                            </em>
                        </p>
                    </td>
                </tr>

                <tr>
                    <td style="padding:20px;width:30%;max-width:30%" align="center">
                        <img style="width:100%;max-width:100%" src="images/DriveVLAW0.png" alt="DriveVLA-W0">
                    </td>
                    <td style="padding:16px;width:100%;vertical-align:middle">
                        <a href="https://arxiv.org/abs/2510.12796" target="_blank" rel="noopener">
                            <span class="papertitle">DriveVLA-W0: World Models Amplify Data Scaling Law in Autonomous Driving</span>
                        </a>
                        <br/>
                        <span>Yingyan Li<sup>*</sup>, <strong>Shuyao Shang</strong><sup>*</sup>, Weisong Liu<sup>*</sup>, Bing Zhan<sup>*</sup>, Haochen Wang<sup>*</sup>, Yuqi Wang, Yuntao Chen, Xiaoman Wang, Yasong An, Chufeng Tang, Lu Hou, Lue Fan<sup>†</sup>, Zhaoxiang Zhang<sup>†</sup></span>
                        <br/>
                        <strong><em>ICLR</em>, 2026</strong>
                        <br>
                        <p>
                            <em>
                                A world-modeling paradigm amplifying data scalability and improving generalization in autonomous driving.
                            </em>
                        </p>
                    </td>
                </tr>


                <!-- DriveDPO (NeurIPS 2025) -->
                <tr>
                    <td style="padding:20px;width:30%;max-width:30%" align="center">
                        <img style="width:100%;max-width:100%" src="images/drivedpo.png" alt="DriveDPO">
                    </td>
                    <td style="padding:16px;width:100%;vertical-align:middle">
                        <a href="https://arxiv.org/abs/2509.17940" target="_blank" rel="noopener">
                            <span class="papertitle">DriveDPO: Policy Learning via Safety DPO for End-to-End Autonomous Driving</span>
                        </a>
                        <br/>
                        <span><strong>Shuyao Shang</strong>, Yuntao Chen, Yuqi Wang, Yingyan Li, Zhaoxiang Zhang<sup
                                class="corr">†</sup></span>
                        <br/>
                        <strong><em>NeurIPS</em>, 2025</strong>
                        <br>
                        <p>
                            <em>
                                A Safety-DPO policy learning framework that unifies policy distillation and
                                trajectory-level safety preference alignment.
                            </em>
                        </p>
                    </td>
                </tr>


                <!-- ResDiff -->
                <tr>
                    <td style="padding:20px;width:30%;max-width:30%" align="center">
                        <img style="width:100%;max-width:100%" src="images/resdiff.png">
                    </td>
                    <td style="padding:16px;width:100%;vertical-align:middle">
                        <a href="https://arxiv.org/abs/2303.08714" target="_blank" rel="noopener">
                            <span class="papertitle">ResDiff: Combining CNN and Diffusion Model for Image Super-Resolution</span>
                        </a>
                        <br/>
                        <span><strong>Shuyao Shang</strong>, Zhengyang Shan, Guangxing Liu, Lunqian Wang, Xinghua Wang, Zekai Zhang, Jinglin Zhang<sup>†</sup></span>
                        <br/>
                        <strong>
                            <em>AAAI</em>, 2024
                        </strong>
                        <br>
                        <p>
                            <em>A hybrid approach that guides diffusion in the residual space relative to a CNN
                                prediction to improve high-frequency detail.</em>
                        </p>
                    </td>
                </tr>

                <!-- 轻量遥感分类 -->
                <tr>
                    <td style="padding:20px;width:30%;max-width:30%" align="center">
                        <img style="width:100%;max-width:100%" src="images/cdcnet.png">
                    </td>
                    <td style="padding:16px;width:100%;vertical-align:middle">
                        <a href="https://ieeexplore.ieee.org/document/10042069" target="_blank" rel="noopener">
                            <span class="papertitle">Faster and Lighter Meteorological Satellite Image Classification by a Lightweight Channel-Dilation-Concatenation Net</span>
                        </a>
                        <br/>
                        <span><strong>Shuyao Shang</strong>, Jinglin Zhang, Xing Wang<sup>†</sup>, Xinghua Wang, Yuanjun Li, Yuanjiang Li</span>
                        <br/>
                        <strong>
                            <em>IEEE J-STARS</em>, 2023</strong>
                        <p>
                            <em>
                                A Channel-Dilation-Concatenation network structure to reduce parameters and inference time while retaining accuracy.
                            </em>
                        </p>
                    </td>
                </tr>

                <!-- CTMU-net -->
                <tr>
                    <td style="padding:20px;width:30%;max-width:30%" align="center">
                        <img style="width:100%;max-width:100%" src="images/ctmunet.png" alt="CTMU-net">
                    </td>
                    <td style="padding:16px;width:100%;vertical-align:middle">
                        <a href="https://ieeexplore.ieee.org/document/10292866" target="_blank" rel="noopener">
                            <span class="papertitle">CTMU-net: An Improved U-Net for Semantic Segmentation of Remote-Sensing Images with Combined Attention Mechanisms</span>
                        </a>
                        <br/>
                        <span>Yuanjun Li, Zhiyu Zhu, Yuanjiang Li, Jinglin Zhang, Xi Li, <strong>Shuyao Shang</strong>, Dewen Zhu<sup>†</sup></span>
                        <br/>
                        <strong>
                            <em>IEEE J-STARS</em>, 2023
                        </strong>
                        <p><em>
                            Enhances U-Net for remote-sensing segmentation via combined attention. </em>
                        </p>
                    </td>
                </tr>

                </tbody>
            </table>

            <!-- Education -->
            <table style="width:100%;border:0;border-spacing:0;border-collapse:separate;margin:0 auto;">
                <tbody>
                <tr>
                    <td style="padding:16px;width:100%;vertical-align:middle">
                        <h2>Education</h2>
                        <ul>
                            <li>
                                <strong>Ph.D. Candidate</strong>, Institute of Automation, Chinese Academy of Sciences,
                                Beijing, China
                                <span style="">(Sept. 2024 – Present)</span>.
                            </li>
                            <li>
                                <strong>B.Eng</strong>., Shandong University, China
                                <span style="">(Sept. 2020 – Jun. 2024) (GPA 93.02/100, rank 2/104)</span>.
                            </li>
                        </ul>
                    </td>
                </tr>
                </tbody>
            </table>

            <!-- Awards -->
            <table style="width:100%;border:0;border-spacing:0;border-collapse:separate;margin:0 auto;">
                <tbody>
                <tr>
                    <td style="padding:16px;width:100%;vertical-align:middle">
                        <h2>Awards &amp; Achievements</h2>
                        <ul>
                            <li>National Scholarship, Shandong University.</li>
                            <li>Outstanding Graduation Thesis &amp; Outstanding Graduate, Shandong University.</li>
                            <!--                    <li>First Prize, Academic Scholarship &amp; Research and Innovation Scholarship, Shandong University</li>-->
                            <!--                    <li>Lanqiao Cup Programming Competition — First Prize (Shandong Province, 4th place)</li>-->
                            <!--                    <li>ICPC Kunming Regional (Bronze), Shandong Provincial Programming Contest (Silver), 2022</li>-->
                        </ul>
                    </td>
                </tr>
                </tbody>
            </table>


            <!-- 页脚（可选） -->
            <table style="width:100%;border:0;border-spacing:0;border-collapse:separate;margin:24px auto 48px;">
                <tbody>
                <tr>
                    <td style="text-align:center;color:#777;font-size:0.9em;">
                        <a href="https://www.easycounter.com/">
                        <img src="https://www.easycounter.com/counter.php?yaoyao"
                        border="0" alt="Hit Counter"></a> visitors since September 2025.
                        <br>
                        © Shuyao Shang
                    </td>
                </tr>
                </tbody>
            </table>

        </td>
    </tr>
    </tbody>
</table>
</body>
</html>
